{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a research Agent"
      ],
      "metadata": {
        "id": "BVqCxnhSlIEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code basiert auf Auszügen von:\n",
        "\n",
        "\n",
        "\n",
        "*   https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_3_pro.ipynb#scrollTo=3CaXL22k8iw4\n",
        "*   https://www.kaggle.com/code/kaggle5daysofai/day-1b-agent-architectures\n",
        "\n"
      ],
      "metadata": {
        "id": "PrVjqxbelROy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wir installieren die Google GenAI libraries\n",
        "%pip install --upgrade --quiet google-genai\n",
        "%pip install google-adk"
      ],
      "metadata": {
        "id": "A_qsUULolHqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importieren der Packages"
      ],
      "metadata": {
        "id": "_rMqE0AQwpyQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1VhblmclD6c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from IPython.display import HTML, Markdown, display\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#\n",
        "#if \"google.colab\" in sys.modules:\n",
        "#    from google.colab import auth\n",
        "#    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "Tpcx9seOsI88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Definieren der notwendigen Umgebungsvariablen.\n",
        "# ACHTUNG: Sie benötigen einen Google API Key\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "UuR2_VAqlqqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiWC14J5vBZ8",
        "outputId": "ff34e9e7-c7f3-4799-edb3-95caaabc7dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google API Key set: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test, ob Aufruf des Modells alleine funktioniert.\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\", contents=\"Explain how Diffusion models work in a few words\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5ETzSsxupoR",
        "outputId": "b70e04e2-7c6f-40fa-bbb6-2a1def82f892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They learn to progressively **denoise** data. To generate, they iteratively remove noise from pure random static until a clear sample emerges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
        "from google.adk.models.google_llm import Gemini\n",
        "from google.adk.runners import InMemoryRunner\n",
        "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
        "from google.genai import types\n",
        "\n",
        "print(\"✅ ADK components imported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzG70UFDl3Lg",
        "outputId": "7200edf9-2f26-4888-8746-482a339b6b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ADK components imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retry_config=types.HttpRetryOptions(\n",
        "    attempts=5,  # Maximum retry attempts\n",
        "    exp_base=7,  # Delay multiplier\n",
        "    initial_delay=1,\n",
        "    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n",
        ")"
      ],
      "metadata": {
        "id": "wB_HVRwWmbSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definieren der Agenten"
      ],
      "metadata": {
        "id": "xb6nj9jKxVII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Research Agent"
      ],
      "metadata": {
        "id": "2Ex3q3CCxYhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "research_agent = Agent(\n",
        "    name=\"ResearchAgent\",\n",
        "    model=Gemini(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        retry_options=retry_config\n",
        "    ),\n",
        "    instruction=\"\"\"You are a world class specialized research agent.\n",
        "    Your only job is to use the Google_search tool to find 2-3 pieces of\n",
        "    relevant information on the given topic and present the findings with\n",
        "    citations.\"\"\",\n",
        "    tools=[google_search],\n",
        "    # Results of this agent will be stored in the session state with this name.\n",
        "    output_key=\"research_findings\",\n",
        ")"
      ],
      "metadata": {
        "id": "TYEJ-yI5mblV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizer Agent"
      ],
      "metadata": {
        "id": "5eDgD5pmxe75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer_agent = Agent(\n",
        "    name=\"SummarizerAgent\",\n",
        "    model=Gemini(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        retry_options=retry_config\n",
        "    ),\n",
        "    # instruction modified to request a bulleted list for a clear output format.\n",
        "    instruction=\"\"\"Read the provided research findings: {research_findings}.\n",
        "    Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
        "    output_key=\"final_summary\",\n",
        ")"
      ],
      "metadata": {
        "id": "WRAp0qdhmgOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Agent"
      ],
      "metadata": {
        "id": "6sKy0NdHxhrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_agent = Agent(\n",
        "    name=\"ResearchCoordinator\",\n",
        "    model=Gemini(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        retry_options=retry_config\n",
        "    ),\n",
        "    # instruction tells root agent HOW to use its tools (which are the other agents).\n",
        "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
        "    1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n",
        "    2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n",
        "    3. Finally, present the final summary clearly to the user as your response.\"\"\",\n",
        "    # wrap sub-agents in `AgentTool` to make them callable tools for the root agent.\n",
        "    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n",
        ")"
      ],
      "metadata": {
        "id": "QjL8tzSTmkFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runner = InMemoryRunner(agent=root_agent)\n",
        "response = await runner.run_debug(\n",
        "    \"What are the latest advancements in Diffusion models and what do they mean for AI?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RecsoyTRmo2v",
        "outputId": "c4e9f198-dc26-4a61-874a-c11cabe98214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ### Created new session: debug_session_id\n",
            "\n",
            "User > What are the latest advancements in Diffusion models and what do they mean for AI?\n",
            "ResearchCoordinator > Latest advancements in diffusion models are significantly enhancing their capabilities in generating high-quality and realistic content, including images, videos, and audio. These models work by iteratively refining random noise into structured data, a process inspired by natural diffusion phenomena.\n",
            "\n",
            "Key advancements and their implications include:\n",
            "\n",
            "*   **Improved Generative Quality and Control:** Diffusion models now achieve state-of-the-art performance in image and audio generation, often surpassing traditional models like Generative Adversarial Networks (GANs). Models like Gen-1 and Gen-2 demonstrate remarkable progress in text-to-video synthesis, producing videos with enhanced detail and control. The development of conditional diffusion models allows for guided generation based on specific criteria.\n",
            "*   **Enhanced Efficiency and Accessibility:** Researchers are focusing on improving the computational efficiency of diffusion models to reduce processing time and energy consumption. Techniques such as latent diffusion models, which operate in compressed data spaces, and optimizations that reduce the number of iterative steps are key to this effort. Open-source communities have also played a crucial role in accelerating their adoption.\n",
            "*   **Expanding Applications:** Beyond image and video generation, diffusion models are finding applications in diverse fields such as drug discovery (generating molecular structures), scientific research (simulating complex systems and generating synthetic data), medical imaging (improving diagnostics and image reconstruction), and even text generation (offering greater control and speed compared to autoregressive models).\n",
            "*   **New Model Architectures and Theoretical Insights:** Innovations like the Poisson Flow Generative Model++ (PFGM++), which integrates diffusion with Poisson Flow principles, are pushing the boundaries of image generation and providing new theoretical understanding. While empirical success is significant, ongoing research aims to strengthen the theoretical underpinnings of diffusion models to facilitate principled methodological innovations.\n",
            "\n",
            "The implications for AI are profound, as diffusion models are revolutionizing generative AI development and enabling more personalized and intelligent automation across various industries. They represent a fundamental shift in how AI learns to create, offering unprecedented stability, quality, and control. The generative AI market, heavily influenced by diffusion models, is projected for substantial growth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNGIu3XixnJt",
        "outputId": "38050077-1955-4563-e287-d2bf6125d885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Event(model_version='gemini-2.5-flash-lite', content=Content(\n",
            "  parts=[\n",
            "    Part(\n",
            "      function_call=FunctionCall(\n",
            "        args={\n",
            "          'request': 'latest advancements in Diffusion models and their implications for AI'\n",
            "        },\n",
            "        id='adk-f4564cd5-53ec-42bc-bc54-bf1128a6f0a8',\n",
            "        name='ResearchAgent'\n",
            "      )\n",
            "    ),\n",
            "  ],\n",
            "  role='model'\n",
            "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  candidates_token_count=23,\n",
            "  prompt_token_count=190,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=190\n",
            "    ),\n",
            "  ],\n",
            "  total_token_count=213\n",
            "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-0f65eb29-b8aa-416f-98a5-6c2c6303d87d', author='ResearchCoordinator', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='7f38f9f1-b42f-4972-b3e6-8c1cd1f79f99', timestamp=1764103713.828066), Event(model_version=None, content=Content(\n",
            "  parts=[\n",
            "    Part(\n",
            "      function_response=FunctionResponse(\n",
            "        id='adk-f4564cd5-53ec-42bc-bc54-bf1128a6f0a8',\n",
            "        name='ResearchAgent',\n",
            "        response={\n",
            "          'result': \"\"\"The latest advancements in diffusion models are significantly enhancing their capabilities in generating high-quality and realistic content, including images, videos, and audio. These models work by iteratively refining random noise into structured data, a process inspired by natural diffusion phenomena.\n",
            "\n",
            "Key advancements and their implications include:\n",
            "\n",
            "*   **Improved Generative Quality and Control:** Diffusion models now achieve state-of-the-art performance in image and audio generation, often surpassing traditional models like Generative Adversarial Networks (GANs). Models like Gen-1 and Gen-2 demonstrate remarkable progress in text-to-video synthesis, producing videos with enhanced detail and control. The development of conditional diffusion models allows for guided generation based on specific criteria.\n",
            "*   **Enhanced Efficiency and Accessibility:** Researchers are focusing on improving the computational efficiency of diffusion models to reduce processing time and energy consumption. Techniques such as latent diffusion models, which operate in compressed data spaces, and optimizations that reduce the number of iterative steps are key to this effort. Open-source communities have also played a crucial role in accelerating their adoption.\n",
            "*   **Expanding Applications:** Beyond image and video generation, diffusion models are finding applications in diverse fields such as drug discovery (generating molecular structures), scientific research (simulating complex systems and generating synthetic data), medical imaging (improving diagnostics and image reconstruction), and even text generation (offering greater control and speed compared to autoregressive models).\n",
            "*   **New Model Architectures and Theoretical Insights:** Innovations like the Poisson Flow Generative Model++ (PFGM++), which integrates diffusion with Poisson Flow principles, are pushing the boundaries of image generation and providing new theoretical understanding. While empirical success is significant, ongoing research aims to strengthen the theoretical underpinnings of diffusion models to facilitate principled methodological innovations.\n",
            "\n",
            "The implications for AI are profound, as diffusion models are revolutionizing generative AI development and enabling more personalized and intelligent automation across various industries. They represent a fundamental shift in how AI learns to create, offering unprecedented stability, quality, and control. The generative AI market, heavily influenced by diffusion models, is projected for substantial growth.\"\"\"\n",
            "        }\n",
            "      )\n",
            "    ),\n",
            "  ],\n",
            "  role='user'\n",
            "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-0f65eb29-b8aa-416f-98a5-6c2c6303d87d', author='ResearchCoordinator', actions=EventActions(skip_summarization=None, state_delta={'research_findings': 'The latest advancements in diffusion models are significantly enhancing their capabilities in generating high-quality and realistic content, including images, videos, and audio. These models work by iteratively refining random noise into structured data, a process inspired by natural diffusion phenomena.\\n\\nKey advancements and their implications include:\\n\\n*   **Improved Generative Quality and Control:** Diffusion models now achieve state-of-the-art performance in image and audio generation, often surpassing traditional models like Generative Adversarial Networks (GANs). Models like Gen-1 and Gen-2 demonstrate remarkable progress in text-to-video synthesis, producing videos with enhanced detail and control. The development of conditional diffusion models allows for guided generation based on specific criteria.\\n*   **Enhanced Efficiency and Accessibility:** Researchers are focusing on improving the computational efficiency of diffusion models to reduce processing time and energy consumption. Techniques such as latent diffusion models, which operate in compressed data spaces, and optimizations that reduce the number of iterative steps are key to this effort. Open-source communities have also played a crucial role in accelerating their adoption.\\n*   **Expanding Applications:** Beyond image and video generation, diffusion models are finding applications in diverse fields such as drug discovery (generating molecular structures), scientific research (simulating complex systems and generating synthetic data), medical imaging (improving diagnostics and image reconstruction), and even text generation (offering greater control and speed compared to autoregressive models).\\n*   **New Model Architectures and Theoretical Insights:** Innovations like the Poisson Flow Generative Model++ (PFGM++), which integrates diffusion with Poisson Flow principles, are pushing the boundaries of image generation and providing new theoretical understanding. While empirical success is significant, ongoing research aims to strengthen the theoretical underpinnings of diffusion models to facilitate principled methodological innovations.\\n\\nThe implications for AI are profound, as diffusion models are revolutionizing generative AI development and enabling more personalized and intelligent automation across various industries. They represent a fundamental shift in how AI learns to create, offering unprecedented stability, quality, and control. The generative AI market, heavily influenced by diffusion models, is projected for substantial growth.'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='f25c0a0e-0025-4955-b990-84294e646d17', timestamp=1764103719.010369), Event(model_version='gemini-2.5-flash-lite', content=Content(\n",
            "  parts=[\n",
            "    Part(\n",
            "      function_call=FunctionCall(\n",
            "        args={\n",
            "          'request': 'Summarize the latest advancements in Diffusion models and their implications for AI, based on the provided research. Key points to cover include improved generative quality, enhanced efficiency, expanding applications, and new model architectures. '\n",
            "        },\n",
            "        id='adk-c9c63dcf-5a33-4d3b-bfa4-67e832ba6210',\n",
            "        name='SummarizerAgent'\n",
            "      )\n",
            "    ),\n",
            "  ],\n",
            "  role='model'\n",
            "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  candidates_token_count=54,\n",
            "  prompt_token_count=652,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=652\n",
            "    ),\n",
            "  ],\n",
            "  total_token_count=706\n",
            "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-0f65eb29-b8aa-416f-98a5-6c2c6303d87d', author='ResearchCoordinator', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='b319aae0-18df-448f-95df-8fd61105b2a9', timestamp=1764103719.011383), Event(model_version=None, content=Content(\n",
            "  parts=[\n",
            "    Part(\n",
            "      function_response=FunctionResponse(\n",
            "        id='adk-c9c63dcf-5a33-4d3b-bfa4-67e832ba6210',\n",
            "        name='SummarizerAgent',\n",
            "        response={\n",
            "          'result': \"\"\"Here's a concise summary of the latest advancements in diffusion models and their implications for AI:\n",
            "\n",
            "*   **Superior Generative Quality and Control:** Diffusion models now excel in generating realistic images, videos, and audio, often outperforming GANs, with advancements like text-to-video synthesis offering enhanced detail and control.\n",
            "*   **Increased Efficiency and Accessibility:** Efforts are underway to make diffusion models computationally more efficient through techniques like latent diffusion and step reduction, further boosted by open-source contributions.\n",
            "*   **Broadening Application Scope:** Their utility is expanding beyond content creation into fields like drug discovery, scientific research, medical imaging, and text generation, demonstrating versatility.\n",
            "*   **Innovative Architectures and Theoretical Foundations:** New model architectures and integrations, such as PFGM++, are pushing generative boundaries, while ongoing research aims to solidify the theoretical underpinnings of these models.\"\"\"\n",
            "        }\n",
            "      )\n",
            "    ),\n",
            "  ],\n",
            "  role='user'\n",
            "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-0f65eb29-b8aa-416f-98a5-6c2c6303d87d', author='ResearchCoordinator', actions=EventActions(skip_summarization=None, state_delta={'final_summary': \"Here's a concise summary of the latest advancements in diffusion models and their implications for AI:\\n\\n*   **Superior Generative Quality and Control:** Diffusion models now excel in generating realistic images, videos, and audio, often outperforming GANs, with advancements like text-to-video synthesis offering enhanced detail and control.\\n*   **Increased Efficiency and Accessibility:** Efforts are underway to make diffusion models computationally more efficient through techniques like latent diffusion and step reduction, further boosted by open-source contributions.\\n*   **Broadening Application Scope:** Their utility is expanding beyond content creation into fields like drug discovery, scientific research, medical imaging, and text generation, demonstrating versatility.\\n*   **Innovative Architectures and Theoretical Foundations:** New model architectures and integrations, such as PFGM++, are pushing generative boundaries, while ongoing research aims to solidify the theoretical underpinnings of these models.\"}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='00030c2f-8b61-42d3-b8d1-8876cb2169b6', timestamp=1764103721.122673), Event(model_version='gemini-2.5-flash-lite', content=Content(\n",
            "  parts=[\n",
            "    Part(\n",
            "      text=\"\"\"Latest advancements in diffusion models are significantly enhancing their capabilities in generating high-quality and realistic content, including images, videos, and audio. These models work by iteratively refining random noise into structured data, a process inspired by natural diffusion phenomena.\n",
            "\n",
            "Key advancements and their implications include:\n",
            "\n",
            "*   **Improved Generative Quality and Control:** Diffusion models now achieve state-of-the-art performance in image and audio generation, often surpassing traditional models like Generative Adversarial Networks (GANs). Models like Gen-1 and Gen-2 demonstrate remarkable progress in text-to-video synthesis, producing videos with enhanced detail and control. The development of conditional diffusion models allows for guided generation based on specific criteria.\n",
            "*   **Enhanced Efficiency and Accessibility:** Researchers are focusing on improving the computational efficiency of diffusion models to reduce processing time and energy consumption. Techniques such as latent diffusion models, which operate in compressed data spaces, and optimizations that reduce the number of iterative steps are key to this effort. Open-source communities have also played a crucial role in accelerating their adoption.\n",
            "*   **Expanding Applications:** Beyond image and video generation, diffusion models are finding applications in diverse fields such as drug discovery (generating molecular structures), scientific research (simulating complex systems and generating synthetic data), medical imaging (improving diagnostics and image reconstruction), and even text generation (offering greater control and speed compared to autoregressive models).\n",
            "*   **New Model Architectures and Theoretical Insights:** Innovations like the Poisson Flow Generative Model++ (PFGM++), which integrates diffusion with Poisson Flow principles, are pushing the boundaries of image generation and providing new theoretical understanding. While empirical success is significant, ongoing research aims to strengthen the theoretical underpinnings of diffusion models to facilitate principled methodological innovations.\n",
            "\n",
            "The implications for AI are profound, as diffusion models are revolutionizing generative AI development and enabling more personalized and intelligent automation across various industries. They represent a fundamental shift in how AI learns to create, offering unprecedented stability, quality, and control. The generative AI market, heavily influenced by diffusion models, is projected for substantial growth.\"\"\"\n",
            "    ),\n",
            "  ],\n",
            "  role='model'\n",
            "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  candidates_token_count=420,\n",
            "  prompt_token_count=900,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=900\n",
            "    ),\n",
            "  ],\n",
            "  total_token_count=1320\n",
            "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-0f65eb29-b8aa-416f-98a5-6c2c6303d87d', author='ResearchCoordinator', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='9d28625b-14dd-4dac-b41f-128128cc92c1', timestamp=1764103721.12459)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3UIM0h_xsPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}